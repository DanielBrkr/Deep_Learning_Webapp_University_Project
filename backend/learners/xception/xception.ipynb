{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xception_benchmark_utility import plot_cnn_performance, plot_cnn_performance_wo_lr\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "print(tf.config.list_logical_devices)\n",
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path locations for project root & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "WORKING_DIR = Path.cwd().resolve()\n",
    "print(f\"Working directory: {WORKING_DIR}\")\n",
    "ROOT_PATH = WORKING_DIR.parent\n",
    "print(f\"Project root path: {ROOT_PATH}\")\n",
    "DATA_PATH = os.path.join(ROOT_PATH.parent.parent, \"Data\", \"Deep_Data\")\n",
    "print(f\"Data path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SAVED_MODELS_DIR = os.path.join(WORKING_DIR, \"saved_models\")\n",
    "print(SAVED_MODELS_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_model = \"Xception\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image & batch size configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32  # usually 32, small batch size, to be able to split validation batches in test- and validation set, with only little images available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  os.path.join(DATA_PATH, 'train_img'),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=24,\n",
    "  image_size=IMG_SIZE,\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "train_ds_np = np.array(train_ds.as_numpy_iterator())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(DATA_PATH, \"train_img\"),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=24,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# Splits the validation dataset batch wise for the test set\n",
    "test_size = int(0.5 * len(val_ds))  # int(0.5 * len(val_ds))\n",
    "test_ds = val_ds.take(test_size)\n",
    "val_ds = val_ds.skip(test_size)\n",
    "\n",
    "# Prints size of reserved batches for each set\n",
    "print('Batches for training -->', train_ds.cardinality())\n",
    "print('Batches for validating -->', val_ds.cardinality())\n",
    "print('Batches for testing -->', test_ds.cardinality())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]], color=\"green\")\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resizing the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "size = (150, 150)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (tf.image.resize_with_pad(x, 150,150), y))\n",
    "validation_ds = val_ds.map(lambda x, y: (tf.image.resize_with_pad(x, 150,150), y))\n",
    "test_ds = test_ds.map(lambda x, y: (tf.image.resize_with_pad(x, 150,150), y))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Conversion to greyscale"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"), cmap = \"Greys\")\n",
    "        plt.title(class_names[labels[i]], color=\"green\")\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.RandomRotation(0.2),\n",
    "        layers.RandomContrast(factor=0.2, seed=24),\n",
    "        keras.layers.RandomBrightness(factor=0.2, seed=24) # Images are usually exposure compensated to middle grey ->\n",
    "        # normalized exposure, hence are random brightness various only sensible for very small values *dani\n",
    "    ]\n",
    ")\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = images[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(\n",
    "            tf.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"), cmap = \"Greys\")\n",
    "        plt.title(int(labels[0]), color=\"green\")\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building a model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_base_model():\n",
    "    base_model = keras.applications.Xception(\n",
    "        weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=(150, 150, 3),\n",
    "        include_top=False,\n",
    "    )  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    # Freezing the base model layers\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create new model on top\n",
    "    inputs = keras.Input(shape=(150, 150, 3))  # (150, 150, 3))\n",
    "    x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "\n",
    "    # Pre-trained Xception weights requires that input be scaled\n",
    "    # from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "    # outputs: `(inputs * scale) + offset`\n",
    "    scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "    x = scale_layer(x)\n",
    "\n",
    "    # The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "    # when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "    # base_model is running in inference mode here.\n",
    "    x = base_model(x, training=False)\n",
    "\n",
    "    return x, inputs\n",
    "\n",
    "# Call this function to compare the optimized model to trained stock model\n",
    "\n",
    "def model_stock():\n",
    "    # WORKING_DIR = Path(__file__).resolve().parents[1]\n",
    "    saved_stock_model_exists = os.path.exists(\n",
    "        os.path.join(WORKING_DIR, r\"xception\\Saved_models\\stock_model\")\n",
    "    )\n",
    "\n",
    "    if saved_stock_model_exists == True:\n",
    "        model_stock = keras.models.load_model(\n",
    "            os.path.join(WORKING_DIR, r\"xception\\Saved_models\\stock_model\")\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        base_model = keras.applications.Xception(\n",
    "            weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "            input_shape=(150, 150, 3),\n",
    "            include_top=False,\n",
    "        )  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "        # Freezing the base model layers\n",
    "        base_model.trainable = False\n",
    "\n",
    "        inputs = keras.Input(shape=(150, 150, 3))\n",
    "        x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "\n",
    "        scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "        x = scale_layer(x)\n",
    "\n",
    "        # The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "        # when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "        # base_model is running in inference mode here.\n",
    "        x = base_model(x, training=False)\n",
    "        x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "        x = keras.layers.Dense(4, activation=\"relu\")(x)\n",
    "        outputs = tf.keras.layers.Softmax()(x)\n",
    "\n",
    "        model_stock = keras.Model(inputs, outputs)\n",
    "\n",
    "        model_stock.compile(\n",
    "            optimizer=\"Nadam\",\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        epochs = 20\n",
    "        model_stock.fit(train_ds, epochs=epochs, validation_data=validation_ds)\n",
    "\n",
    "    # model_stock.save(os.path.join(WORKING_DIR,r\"saved_models\\stock_model\"))\n",
    "\n",
    "    return model_stock"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup of top layer hyperparameter optimization\n",
    "We assume that hyperparameter adjustments make the most sense on the top layer, as this is not per se part of the Xception architecture and adjusted to our problem, extensive parameters search while fine tuning would make the use of transfer learning somewhat redundant"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the top layer - change \"compile_base\" if you want to train the base model, loads otherwise a prior base model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "\n",
    "\n",
    "def model_top_grad_student_descent():\n",
    "    x, inputs = build_base_model()\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "\n",
    "    #### Custom Custom Top Layer\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(4, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Softmax()(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    optimizer_freeze = keras.optimizers.Nadam()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer_freeze,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_top_simple_classifier():\n",
    "    x, inputs = build_base_model()\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "\n",
    "    #### Custom Custom Top Layer\n",
    "    x = keras.layers.Dense(4, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Softmax()(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    optimizer_freeze = keras.optimizers.Nadam()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer_freeze,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "### Top Layer for hyperparameter search\n",
    "def model_top_layer(hp):\n",
    "\n",
    "    x, inputs = build_base_model()\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "\n",
    "    for i in range(hp.Int(\"layers\", 0, 3)):\n",
    "        if i > 0:\n",
    "            x = keras.layers.Dense(\n",
    "                units=hp.Int(\"units_\" + str(i), 64, 961, step=64),\n",
    "                activation=hp.Choice(\"act_\" + str(i), [\"relu\", \"selu\"]),\n",
    "            )(x)\n",
    "            x = keras.layers.Dropout(\n",
    "                rate=hp.Float(\n",
    "                    \"dropout_\" + str(i),\n",
    "                    min_value=0.2,\n",
    "                    max_value=0.5,\n",
    "                    default=0.20,\n",
    "                    step=0.10,\n",
    "                )\n",
    "            )(\n",
    "                x\n",
    "            )  # Regularize with dropout\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    x = keras.layers.Dense(4, activation=hp.Choice(\"activation\", [\"relu\", \"selu\"]))(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Softmax()(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    optimizer_freeze = keras.optimizers.Nadam()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer_freeze,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sets runlog ids hyperparameter and fine tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(Path.cwd(), \"logs\")\n",
    "print(f\"TensorBoard logs saved to follwing dir: {LOG_DIR}\")\n",
    "\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(LOG_DIR, run_id), run_id\n",
    "\n",
    "\n",
    "run_logdir, run_id = get_run_logdir()\n",
    "print(run_id)\n",
    "print(os.path.join(\"hyperparam_logs\", run_id))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup of top layer hyperparameter search\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner_typ_1 = \"random\"\n",
    "tuner_typ_2 = \"hyper\"\n",
    "tuner_typ_3 = \"bayes\"\n",
    "\n",
    "tuner_select = tuner_typ_1\n",
    "\n",
    "tuner_switch_on = \"on\"\n",
    "tuner_switch_off = \"off\"\n",
    "\n",
    "tuner_state = tuner_switch_off"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if tuner_state == tuner_switch_off:\n",
    "    print(\"No hyperparameter tuning\")\n",
    "\n",
    "    model = model_top_grad_student_descent()\n",
    "    model.summary()\n",
    "    best_model = model\n",
    "\n",
    "else:\n",
    "    model = model_top_layer(keras_tuner.HyperParameters())\n",
    "    model.summary()\n",
    "\n",
    "    if tuner_select == tuner_typ_1:\n",
    "        tuner = keras_tuner.RandomSearch(\n",
    "            hypermodel=model_top_layer,\n",
    "            objective=\"val_loss\",\n",
    "            max_trials=10,\n",
    "            executions_per_trial=3,\n",
    "            overwrite=True,\n",
    "            directory=\"hyperparam_logs\",\n",
    "            project_name=run_id,\n",
    "        )\n",
    "\n",
    "        tuner.search_space_summary()\n",
    "        tuner.search(\n",
    "            train_ds,\n",
    "            epochs=3,\n",
    "            validation_data=val_ds,\n",
    "            callbacks=[\n",
    "                keras.callbacks.TensorBoard(os.path.join(\"hyperparam_logs\", run_id))\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    elif tuner_select == tuner_typ_2:\n",
    "        tuner = keras_tuner.Hyperband(\n",
    "            model_top_layer,\n",
    "            objective=\"val_loss\",\n",
    "            max_epochs=30,\n",
    "            factor=3,\n",
    "            directory=\"hyperparam_logs\",\n",
    "            project_name=run_id,\n",
    "        )\n",
    "\n",
    "        early_stop_hyperband = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=3\n",
    "        )\n",
    "\n",
    "        tuner.search(\n",
    "            train_ds,\n",
    "            epochs=2,\n",
    "            validation_data=val_ds,\n",
    "            callbacks=[\n",
    "                keras.callbacks.TensorBoard(os.path.join(\"hyperparam_logs\", run_id)),\n",
    "                early_stop_hyperband,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    elif tuner_select == tuner_typ_3:\n",
    "        tuner = keras_tuner.BayesianOptimization(\n",
    "            model_top_layer,\n",
    "            objective=\"val_loss\",\n",
    "            max_trials=10,\n",
    "            num_initial_points=2,\n",
    "            alpha=0.0001,\n",
    "            beta=2.6,\n",
    "            seed=24,\n",
    "            directory=\"hyperparam_logs\",\n",
    "            project_name=run_id,\n",
    "        )\n",
    "        tuner.search(\n",
    "            train_ds,\n",
    "            epochs=3,\n",
    "            validation_data=val_ds,\n",
    "            callbacks=[\n",
    "                keras.callbacks.TensorBoard(os.path.join(\"hyperparam_logs\", run_id))\n",
    "            ],\n",
    "        )\n",
    "    else:\n",
    "        print(\"Invalid Tuner selected\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Training the top layer with the best hps\n",
    "\n",
    "model_top = best_model\n",
    "\n",
    "early_stop_callback_top = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "epochs = 20\n",
    "history_top_training = model_top.fit(train_ds, epochs=epochs, validation_data=validation_ds, callbacks = [early_stop_callback_top, PlotLossesKeras(), tensorboard_cb])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cnn_performance_wo_lr(history_top_training)\n",
    "\n",
    "with PdfPages(os.path.join(run_logdir, run_id +  \"history_top_tuning\"  'performance.pdf')) as pdf:\n",
    "    pdf.savefig(plot_cnn_performance_wo_lr(history_top_training), bbox_inches='tight')\n",
    "\n",
    "keras.backend.clear_session() #releases allocated memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save(os.path.join(run_logdir, run_id +\"_history_top_training.npy\"), history_top_training.history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard allows to monitor performance\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --reload_multifile True --logdir = #-removed-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get model summary as a string\n",
    "def get_summary_str(model):\n",
    "    lines = []\n",
    "    model.summary(print_fn=lines.append)\n",
    "    # Add initial spaces to avoid markdown formatting in TensorBoard\n",
    "    return \"    \" + \"\\n    \".join(lines)\n",
    "\n",
    "\n",
    "# Write a string to TensorBoard (2.x)\n",
    "def write_string_summary_v2(writer, s, run_id):\n",
    "    with writer.as_default():\n",
    "        tf.summary.text(\n",
    "            \"Model configuration for \" + run_id + \"\\n Tuner: \" + tuner_select,\n",
    "            #  \"\\n Hyperparameters: \" + tuner.get_best_models(num_models=1)\n",
    "            s,\n",
    "            step=0,\n",
    "        )\n",
    "\n",
    "\n",
    "writer = tf.summary.create_file_writer(os.path.join(\"logs\", run_id))\n",
    "write_string_summary_v2(writer, get_summary_str(model), run_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fancy progressbar, live plotting for each epoch and callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "# muss von hand installiert werden bei einem conda env *dani\n",
    "\n",
    "ft_learning_rate = 1e-5  # learning rate for fine tuning default: 1e-5 limits for adaptive optimizers the maximum learning rate\n",
    "\n",
    "# Warmstarting/Ramp Up of learning rate, gets to specified learning rate after 10 epochs\n",
    "def scheduler_fine_tuning_ramp_up(epoch, lr):\n",
    "    if epoch > 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(0.01)\n",
    "\n",
    "\n",
    "def scheduler_fine_tuning_ramp_up_aggressive(epoch, lr):\n",
    "    if epoch > 20:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(0.1)\n",
    "\n",
    "\n",
    "def scheduler_fine_tuning_decay(epoch, lr):\n",
    "    if epoch > 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.01)\n",
    "\n",
    "\n",
    "def scheduler_fine_tuning_decay_aggressive(epoch, lr):\n",
    "    if epoch > 20:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "def scheduler_fine_tuning_monitoring(epoch, lr):\n",
    "    return lr\n",
    "\n",
    "\n",
    "learning_rate_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "    scheduler_fine_tuning_ramp_up\n",
    ")\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=10, restore_best_weights=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "\n",
    "keras.backend.clear_session()  # releases allocated memory\n",
    "\n",
    "best_model = model_top\n",
    "\n",
    "best_model.compile(\n",
    "    # 1-e5\n",
    "    optimizer=keras.optimizers.Nadam(1e-5),  # Low learning rate\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "best_model.trainable = True\n",
    "best_model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# no early stopping\n",
    "callbacks_ft = [\n",
    "    tensorboard_cb,\n",
    "    TqdmCallback(verbose=0),\n",
    "    learning_rate_callback,\n",
    "    PlotLossesKeras(),\n",
    "]\n",
    "# not logging tensorboard, however early stop\n",
    "# callbacks_ft = [TqdmCallback(verbose=0), learning_rate_callback, early_stop_callback, PlotLossesKeras()]\n",
    "# all possible callbacks\n",
    "# callbacks_ft = [tensorboard_cb,TqdmCallback(verbose=0), learning_rate_callback, early_stop_callback, PlotLossesKeras()]\n",
    "\n",
    "epochs = 20\n",
    "history_fine_tuning = best_model.fit(\n",
    "    train_ds, epochs=epochs, validation_data=validation_ds, callbacks=callbacks_ft\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_cnn_performance_wo_lr(history_fine_tuning)\n",
    "np.save(os.path.join(run_logdir, run_id +\"_history_fine_training.npy\"), history_fine_tuning.history)\n",
    "\n",
    "with PdfPages(os.path.join(run_logdir, run_id +\"history_fine_tuning\"+ 'performance.pdf')) as pdf:\n",
    "    pdf.savefig(plot_cnn_performance_wo_lr(history_fine_tuning), bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fancy plot resulting charts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import palettable\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "plt.rc('font', family='serif', size=12)\n",
    "\n",
    "font = font_manager.FontProperties(family='serif',\n",
    "                                   style='normal', size=12)\n",
    "\n",
    "def cm2inch(value):\n",
    "        return value / 2.54\n",
    "\n",
    "def plot_lr_loss():\n",
    "\n",
    "    fig2, axes2 =   plt.subplots(nrows=1, ncols=1, figsize=(cm2inch(40), cm2inch(10))) #title = 'Training Analysis')\n",
    "\n",
    "    axes2.set_prop_cycle('color', palettable.matplotlib.Plasma_4.mpl_colors)\n",
    "\n",
    "    plt.semilogx(\n",
    "    history_fine_tuning.history['lr'],\n",
    "    history_fine_tuning.history['loss'],\n",
    "    lw=1)\n",
    "\n",
    "\n",
    "    plt.title('Learning rate vs. loss', size=16)\n",
    "    plt.xlabel('Learning rate', size=14)\n",
    "    plt.ylabel('Loss', size=14);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_lr_loss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prep for confusion matrix\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    cohen_kappa_score,\n",
    "    precision_recall_curve,\n",
    "    PrecisionRecallDisplay,\n",
    "    average_precision_score,\n",
    ")\n",
    "from itertools import cycle\n",
    "\n",
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "\n",
    "print(image_batch)\n",
    "\n",
    "best_model_pre_ft = model_stock()\n",
    "\n",
    "predictions_best_model = best_model.predict(image_batch)  # .flatten()\n",
    "predictions_initial_model = best_model_pre_ft.predict(image_batch)\n",
    "\n",
    "y_pred = np.argmax(predictions_best_model, axis=-1)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(label_batch, y_pred)\n",
    "balance_accuracy = balanced_accuracy_score(\n",
    "    label_batch, y_pred\n",
    ")  # Balance accuracy for the unbalanced test dataset\n",
    "kappa = cohen_kappa_score(\n",
    "    label_batch, y_pred\n",
    ")  # Overall accuracy of the model given the distributions of the target and predicted classes:\n",
    "recall = recall_score(label_batch, y_pred, average=None)  #  True positive rate\n",
    "precision = precision_score(\n",
    "    label_batch, y_pred, average=None\n",
    ")  # Ability of the classifier not to label as positive a sample that is negative.\n",
    "f1 = f1_score(\n",
    "    label_batch, y_pred, average=None\n",
    ")  #  Harmonic mean of precision & recall for each class individually\n",
    "\n",
    "array_met = np.concatenate((precision, recall))\n",
    "array_met = np.concatenate((array_met, f1))\n",
    "array_acc = np.array([accuracy, balance_accuracy])\n",
    "\n",
    "statistical_metrics = np.concatenate((array_acc, array_met))\n",
    "\n",
    "print(\"\\n--- Performance evaluation on test --- \\n\")\n",
    "print(f\"The accuracy of the best model: {accuracy}%\")\n",
    "print(f\"The balanced accuracy of the best model: {balance_accuracy}%\")\n",
    "print(f\"The precision of the best model: {precision}%\")\n",
    "print(f\"The recall of the best model: {recall}%\")\n",
    "print(f\"The f1 score of the best model: {f1}%\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_comparative():\n",
    "\n",
    "    import seaborn as sns\n",
    "\n",
    "    plt.rc(\"font\", family=\"serif\", size=16)\n",
    "    plt.rcParams[\"axes.titlepad\"] = 20\n",
    "\n",
    "    confusion_mtx = tf.math.confusion_matrix(label_batch, np.argmax(predictions_best_model,axis=-1))\n",
    "    confusion_mtx_initial = tf.math.confusion_matrix(label_batch, np.argmax(predictions_initial_model,axis=-1))\n",
    "\n",
    "    fig3, axes3 = plt.subplots(nrows=1, ncols=2, figsize=(cm2inch(40), cm2inch(10)), sharey='row') #title = 'Training Analysis')\n",
    "\n",
    "    sns.heatmap(confusion_mtx_initial, ax=axes3[0],\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names,\n",
    "                annot=True, fmt='g')\n",
    "\n",
    "    sns.heatmap(confusion_mtx, ax=axes3[1],\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names,\n",
    "                annot=True, fmt='g')\n",
    "\n",
    "    axes3[0].title.set_text('Stock Model')\n",
    "    axes3[1].title.set_text('Custom Fine-Tuned Model')\n",
    "\n",
    "    for ax in axes3.flat:\n",
    "             ax.set_ylabel('Prediction')\n",
    "             ax.set_xlabel('Ground Truth')\n",
    "\n",
    "    sns.reset_orig()\n",
    "\n",
    "\n",
    "def plot_test_statistical_metrics(statistical_metrics):\n",
    "\n",
    "    plt.rcParams[\"axes.titlepad\"] = 20\n",
    "    plt.rc(\"font\", family=\"serif\", size=16)\n",
    "    fig3, axes3 =   plt.subplots(nrows=1, ncols=1, figsize=(cm2inch(40), cm2inch(10))) #title = 'Training Analysis')\n",
    "\n",
    "    axes3.grid(which=\"major\")\n",
    "    width = 0.7\n",
    "\n",
    "    axes3.set_prop_cycle('color', palettable.matplotlib.Plasma_12.mpl_colors)\n",
    "    for i in range(14):\n",
    "\n",
    "        axes3.bar(i, height=statistical_metrics[i], width=width, ecolor='black', lw=3, capsize=5,\n",
    "              alpha=1, label='UR 10e', zorder=3)\n",
    "\n",
    "    plt.title('Statistical Metrics on the Test Set \\n Custom Fine-Tuned Model', size=16)\n",
    "    plt.xlabel(r'p = precision, r = recall, f1 = f1-score', size=16)\n",
    "    plt.ylabel(r'%', size=16);\n",
    "\n",
    "    plt.xticks(np.arange(0, 14, step=1), (\n",
    "        r'accuracy', 'balanced \\n accuracy', 'p dent', 'p other', 'p rim', \"p scratch\", \"r1\", \"r2\", \"r3\", \"r4\", \"f1_1\", \"f1_2\",\"f1_3\", \"f14\"  ))\n",
    "\n",
    "    # Achtung je nach batch kann sich die Reihenfolge von den labels ändern?\n",
    "    plt.setp(axes3.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "    axes3.set_ylim(0, 1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Project_Paperwork.Legacy_Code.xception import xception_benchmark_utility\n",
    "eval_test = xception_benchmark_utility.run_test_eval_10(model,test_ds)\n",
    "eval_test.describe()\n",
    "plot_test_statistical_metrics(statistical_metrics=xception_benchmark_utility.run_evaluation_on_test(model,test_ds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_test_eval_xception(eval_dataframe):\n",
    "    \"\"\"Plots the statistical metrics from the function run_evaluation_on_test() \"\"\"\n",
    "\n",
    "    plt.rcParams[\"axes.titlepad\"] = 20\n",
    "    plt.rc(\"font\", family=\"serif\", size=16)\n",
    "    fig3, axes3 = plt.subplots(\n",
    "        nrows=1, ncols=1, figsize=(cm2inch(40), cm2inch(10))\n",
    "    )  # title = 'Training Analysis')\n",
    "\n",
    "    axes3.grid(which=\"major\")\n",
    "    width = 0.5\n",
    "\n",
    "    eval_dataframe_stats = eval_dataframe.describe()\n",
    "\n",
    "    # reindexing alphabetical class name order (1. dent, 2. other, 3. rim, 4. scratch) to scratch dent rim other\n",
    "    columns_to_swap = [\n",
    "            \"accuracy\",\n",
    "            \"balanced accuracy\",\n",
    "            \"cohens kappa\",\n",
    "            \"p scratch\",\n",
    "            \"p dent\",\n",
    "            \"p rim\",\n",
    "            \"p other\",\n",
    "\n",
    "            \"r4\",\n",
    "            \"r1\",\n",
    "            \"r3\",\n",
    "            \"r2\",\n",
    "\n",
    "\n",
    "            \"f1_4\",\n",
    "            \"f1_1\",\n",
    "            \"f1_3\",\n",
    "            \"f1_2\"]\n",
    "\n",
    "\n",
    "    eval_dataframe_stats = eval_dataframe_stats.reindex(columns = columns_to_swap)\n",
    "    eval_dataframe_stats.columns = [\"accuracy\",\n",
    "        \"balanced accuracy\",\n",
    "        \"cohens kappa\",\n",
    "        \"precision scratch\",\n",
    "        \"precision dent\",\n",
    "        \"precision rim\",\n",
    "        \"precision other\",\n",
    "        \"recall scratch\",\n",
    "        \"recall dent\",\n",
    "        \"recall rim\",\n",
    "        \"recall other\",\n",
    "        \"f1 scratch\",\n",
    "        \"f1 dent\",\n",
    "        \"f1 rim\",\n",
    "        \"f1 other\"]\n",
    "\n",
    "    axes3.set_prop_cycle(\"color\", palettable.matplotlib.Plasma_12.mpl_colors)\n",
    "    for i in range(15):\n",
    "        axes3.bar(\n",
    "            i,\n",
    "            yerr = eval_dataframe_stats.iloc[2,i],\n",
    "            height=eval_dataframe_stats.iloc[1,i],\n",
    "            width=width,\n",
    "            ecolor=\"black\",\n",
    "            lw=3,\n",
    "            capsize=5,\n",
    "            alpha=1,\n",
    "            label=\"UR 10e\",\n",
    "            zorder=3,\n",
    "        )\n",
    "\n",
    "    plt.title(\"Statistical Metrics on the Test Set\", size=16)\n",
    "   # plt.xlabel(r\"p = precision, r = recall, f1 = f1-score\", size=16)\n",
    "    plt.ylabel(r\"%\", size=16)\n",
    "    #   plt.suptitle(\"p = precision\", y=1.05, fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "    plt.xticks(\n",
    "\n",
    "         np.arange(0, 15, step=1),\n",
    "        (list(eval_dataframe_stats.columns.values))\n",
    "        ),\n",
    "\n",
    "    # Achtung je nach batch kann sich die Reihenfolge von den labels ändern?\n",
    "    plt.setp(axes3.get_xticklabels(), rotation=45, horizontalalignment=\"right\")\n",
    "\n",
    "    axes3.set_ylim(0)\n",
    "\n",
    "    return eval_dataframe_stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_stats = plot_test_eval_xception(eval_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "def concat_tensor_and_labels():\n",
    "    \"\"\"Ist hier für Testzwecke um mit dem tf.Data Object die Test Peformance in um das test_ds in einem rutsch zu evaluieren \"\"\"\n",
    "\n",
    "    predictions = np.array([])\n",
    "   # predictions_prob = np.array([])\n",
    "    labels = np.array([])\n",
    "    for x, y in test_ds:\n",
    "        predictions = np.concatenate([predictions, np.argmax(model.predict(x), axis=-1)])\n",
    "        labels = np.concatenate([labels, y.numpy()])\n",
    "\n",
    "    return predictions,   labels\n",
    "\n",
    "y_pred, labels = concat_tensor_and_labels()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_test, y_pred):\n",
    "    y_test = y_test.reshape((-1, 1))\n",
    "    y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "    n_classes = 4\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    thresholds = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], thresholds[i] = roc_curve(\n",
    "            y_test[:, i], y_pred[:], drop_intermediate=False\n",
    "        )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    # plt.figure(figsize=(10,5))\n",
    "    plt.figure(dpi=600)\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"macro\"],\n",
    "        tpr[\"macro\"],\n",
    "        label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "        color=\"navy\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"darkgreen\", \"yellow\"])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            color=color,\n",
    "            lw=lw,\n",
    "            label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic (ROC) curve\")\n",
    "    plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(labels.shape)\n",
    "print(y_pred.shape)\n",
    "print(labels.reshape((-1, 1)).shape)\n",
    "plot_roc_curve(labels, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_pred):\n",
    "\n",
    "  n_classes = len(np.unique(y_test))\n",
    "  y_test = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "  y_pred = label_binarize(y_pred, classes=np.arange(n_classes))\n",
    "\n",
    "  # Compute ROC curve and ROC area for each class\n",
    "  fpr = dict()\n",
    "  tpr = dict()\n",
    "  roc_auc = dict()\n",
    "  for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "  # Compute micro-average ROC curve and ROC area\n",
    "  fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "  roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "  # First aggregate all false positive rates\n",
    "  all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "  # Then interpolate all ROC curves at this points\n",
    "  mean_tpr = np.zeros_like(all_fpr)\n",
    "  for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "  # Finally average it and compute AUC\n",
    "  mean_tpr /= n_classes\n",
    "\n",
    "  fpr[\"macro\"] = all_fpr\n",
    "  tpr[\"macro\"] = mean_tpr\n",
    "  roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "  # Plot all ROC curves\n",
    "  plt.figure(figsize=(cm2inch(50),cm2inch(15)))\n",
    "  plt.figure(dpi=300)\n",
    "  lw = 2\n",
    "  plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\", linestyle=\":\", linewidth=4,)\n",
    "\n",
    "  plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\", linestyle=\":\", linewidth=4,)\n",
    "\n",
    "  colors = cycle([\"aqua\", \"darkorange\", \"darkgreen\", \"yellow\", \"blue\"])\n",
    "  for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),)\n",
    "\n",
    "  plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlabel(\"False Positive Rate\")\n",
    "  plt.ylabel(\"True Positive Rate\")\n",
    "  plt.title(\"Receiver Operating Characteristic (ROC) curve\")\n",
    "  plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_roc_curve(labels,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
